<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<title>Face Detection</title>
		<link rel="manifest" href="manifest.json">
		<meta name="theme-color" content="#4CAF50">
		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black">
		<link rel="apple-touch-icon" href="icons/icon-192.png">
		<style>
			*{margin:0;padding:0;box-sizing:border-box}
			body{font-family:sans-serif;display:flex;flex-direction:column;align-items:center;padding:1rem;background:#f4f4f9;color:#333;}
			h1{font-size:2rem;margin-bottom:1rem;}
			.face-detection-container{display:flex;flex-wrap:wrap;gap:1rem;justify-content:center;align-items:center;width:100%;max-width:768px;}
			.video-wrapper{position:relative;width:100%;}
			video{border-radius:8px;transform:scaleX(-1);max-width:100%;height:auto;object-fit:contain;}
			.overlay{position:absolute;top:0;left:0;width:100%;height:100%;pointer-events:none;display:none;}
			.snapshot{border:2px solid #333;background:rgba(255,255,255,0.7);box-shadow:0 4px 10px rgba(0,0,0,0.1);display:none;max-width:100%;height:auto;}
			label{margin:0.5rem;}
			#registrationMessage{margin-top:0.5rem;color:red;}
			@media (max-width:600px){.face-detection-container{flex-direction:column}}
		</style>
		
		<!-- Load face-api core library first -->
		<script src="./js/face-api.min.js"></script>
		<!-- Then load the warm-up helper that depends on face-api -->
		<script src="./js/faceapi_warmup.js"></script>
		<script>
			function urlReplace(url) {
				window.location.replace(url); 
			}
		</script>
	</head>
	<body>
		<h1>Face Detection</h1>
		<a href="#" onclick="urlReplace('index.html')">Go to Index</a><br>
		<!-- Add user ID and name inputs -->
		<label>User ID: <input type="text" id="userIdInput" placeholder="Enter user ID"></label>
		<label>User Name: <input type="text" id="userNameInput" placeholder="Enter user name"></label><br>
		<div id="registrationMessage" style="color:red; margin-top:10px;"></div>
		<script>
			function getParam(name) {
				const params = new URLSearchParams(window.location.search);
				return params.get(name);
			}
			document.addEventListener('DOMContentLoaded', () => {
				const defId = getParam('userid') || 'test001';
				const defName = getParam('username') || 'test';
				document.getElementById('userIdInput').value = defId;
				document.getElementById('userNameInput').value = defName;
			});
		</script>
		
		<div class="face-detection-container"  style="display:flex;gap:1rem;flex-wrap:wrap;justify-content:center;">
			<div class="video-wrapper">
				<video id="video" width="640" height="480" autoplay playsinline muted></video>
				<!-- Hidden canvas for inference: captures each video frame to send to the worker for face detection -->
				<canvas id="canvas" class="overlay"></canvas>
				<!-- Overlay canvas for drawing facial landmarks on top of the video -->
				<canvas id="canvas2" class="overlay"></canvas>
				<!-- Overlay canvas for drawing face bounding boxes and confidence scores -->
				<canvas id="canvas3" class="overlay"></canvas>
			</div>
			<!-- Snapshot canvas: displays the captured face image along with the confidence percentage -->
			<canvas id="canvas_output" class="snapshot"></canvas>
		</div>

		<script>
			/**
			 * ================================
			 * Face-API Configuration
			 * -------------------------------
			 * faceapi_action
			 *   • "verify"   – Compare the live video frame against a previously
			 *     registered reference descriptor (used in a face-verification flow).
			 *   • "register" – Capture the detected face descriptor and store it as
			 *     a new reference (used when enrolling a new user).
			 *
			 * face_detector_options_setup
			 *   These options are forwarded to face-api.js TinyFaceDetector and allow
			 *   you to balance performance vs. accuracy according to your use-case.
			 *   • inputSize        – Dimension (square) of the NN input. Larger numbers
			 *                         improve accuracy but require more computation.
			 *   • scoreThreshold   – Minimum confidence score (0-1) that a detection
			 *                         must reach to be considered valid. 0.8 = 80%.
			 *   • maxDetectedFaces – Hard limit on how many faces should be processed
			 *                         per frame. Keeping it at 1 speeds things up when
			 *                         you only care about the user in front of the
			 *                         camera.
			 * ================================
			 */
			var faceapi_action = "register"; // verify, register
			var warmup_completed = [camera_start, video_face_detection];
			var face_detector_options_setup = {
				inputSize: 128,
				scoreThreshold: 0.75, // 0.8 = 80%
				maxDetectedFaces: 1,
			};
		</script>
	</body>
</html>
